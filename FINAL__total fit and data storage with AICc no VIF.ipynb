{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tools as st\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_data(experimental_file, response_file, response):\n",
    "    'imports data'\n",
    "    'experimental_file = experimental design csv filename i.e experimental.csv'\n",
    "    'response_file = results csv filename i.e Response.csv'\n",
    "    'response = reponse name: i.e rheomix final deg time min or rheomix stability time min'\n",
    "    \n",
    "    experimental_df = pd.read_csv(experimental_file)\n",
    "    response_df = pd.read_csv(response_file)\n",
    "    \n",
    "    X = experimental_df[experimental_df.columns.values.tolist()[1:]].values\n",
    "    y = response_df[response].values\n",
    "    max1 = max(y)\n",
    "    min1 = min(y)\n",
    "\n",
    "    y_norm = [2*((i-min1)/(max1-min1)) - 1 for i in y]\n",
    "    \n",
    "    \n",
    "    X_linear = X\n",
    "    linear_terms = experimental_df.columns.values.tolist()[1:]\n",
    "    \n",
    "    return y_norm, X_linear, linear_terms, experimental_df, response_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def X_gen(model, X_linear):\n",
    "\n",
    "    for i, j in enumerate(model):\n",
    "        \n",
    "        if i == 0 and len(j) == 2: \n",
    "            X_new = X_linear[:, model[0][1]]\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            if len(j) == 2:\n",
    "                add = X_linear[:, j[1]]\n",
    "\n",
    "            if len(j) == 3:\n",
    "                add = X_linear[:, j[1]]*X_linear[:, j[2]]\n",
    "\n",
    "            X_new2 = np.column_stack((X_new, add))\n",
    "            X_new = X_new2\n",
    "\n",
    "    \n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "# linear_terms = experimental_df.columns.values.tolist()[1:]\n",
    "\n",
    "\n",
    "\n",
    "def fit_model(experimental_file, response_file, response, k_folds):\n",
    "    \n",
    "\n",
    "    total_subset = []\n",
    "\n",
    "    \n",
    "    y, X_linear, linear_terms, experimental_df, response_df = import_data(experimental_file, response_file, response)\n",
    "    y1 = np.array(y)\n",
    "    lin_terms = []\n",
    "    AIC_prev = 1000\n",
    "    av_score_prev = 0\n",
    "\n",
    "    for i in range(len(linear_terms)):\n",
    "        term = linear_terms[i]\n",
    "        key = i\n",
    "        lin_terms.append([term, i])\n",
    "\n",
    "    cnt = 0\n",
    "    for i in range(len(lin_terms)):\n",
    "        for j in combinations(lin_terms, i+1):\n",
    "            linear_terms = list(j)\n",
    "\n",
    "\n",
    "            model = [a for a in linear_terms]\n",
    "            cnt+=1\n",
    "\n",
    "            X = X_gen(model, X_linear)\n",
    "\n",
    "            model_fit = sm.OLS(y, X)\n",
    "            results = model_fit.fit()\n",
    "            AIC_cur = st.eval_measures.aicc(results.llf, results.nobs, results.df_model)\n",
    "            AICc = AIC_cur\n",
    "            \n",
    "            if len(model) == 1:\n",
    "                \n",
    "                X1 = X.reshape(len(X), 1)\n",
    "                model_obj = LinearRegression(fit_intercept=False)\n",
    "                my_cv = ShuffleSplit(n_splits=k_folds, test_size= 1/k_folds, random_state=0)\n",
    "\n",
    "                score = cross_val_score(model_obj, X1, y1, cv=my_cv)\n",
    "                av_score = sum(score)/len(score)\n",
    "            \n",
    "            else:\n",
    "            \n",
    "                model_obj = LinearRegression(fit_intercept=False)\n",
    "                my_cv = ShuffleSplit(n_splits= k_folds, test_size= 1/k_folds, random_state=0)\n",
    "\n",
    "                score = cross_val_score(model_obj, X, y1, cv=my_cv)\n",
    "                av_score = sum(score)/len(score)\n",
    "            \n",
    "            model_name = '--'\n",
    "            for i in model:\n",
    "                \n",
    "                model_name += i[0] + \"--\"\n",
    "\n",
    "            dictionary = {'AIC': results.aic, 'AICc': AICc, 'BIC': results.bic, 'Cond_No': results.condition_number, 'Model': model_name,\n",
    "                          'r2': results.rsquared, 'No_terms': len(model), 'Kfold': av_score}\n",
    "            total_subset.append(dictionary)\n",
    "            \n",
    "                    \n",
    "                    \n",
    "            if AIC_cur < AIC_prev:\n",
    "\n",
    "                AIC_prev = AIC_cur\n",
    "                final_model = [model, results, AIC_cur]\n",
    "                \n",
    "            if av_score_prev < av_score:\n",
    "\n",
    "                av_score_prev= av_score\n",
    "                final_model_kfold = [model, results, av_score]                \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "            poss_terms = []\n",
    "            for i in range(len(linear_terms)):\n",
    "                for j in range(len(linear_terms)): \n",
    "                    if i < j:\n",
    "                        poss_terms.append([linear_terms[i][0] + '*' + linear_terms[j][0],  linear_terms[i][1], linear_terms[j][1]])\n",
    "\n",
    "\n",
    "\n",
    "            for m in range(1, len(poss_terms) + 1):\n",
    "                for k in combinations(poss_terms, m):\n",
    "\n",
    "                    model = [a for a in linear_terms]\n",
    "                    for i in range(m):\n",
    "                        model.append(k[i])\n",
    "\n",
    "                    cnt +=1\n",
    "                    X = X_gen(model, X_linear)\n",
    "\n",
    "                    model_fit = sm.OLS(y, X)\n",
    "                    results = model_fit.fit()\n",
    "                    AIC_cur = st.eval_measures.aicc(results.llf, results.nobs, results.df_model)\n",
    "                    AICc = AIC_cur\n",
    "                    \n",
    "                    model_obj = LinearRegression(fit_intercept=False)\n",
    "                    my_cv = ShuffleSplit(k_folds, test_size= 1/k_folds, random_state=0)\n",
    "                    \n",
    "                    score = cross_val_score(model_obj, X, y1, cv=my_cv)\n",
    "                    av_score = sum(score)/len(score)\n",
    "                    \n",
    "                    model_name = '--'\n",
    "                    for i in model:\n",
    "\n",
    "                        model_name += i[0] + \"--\"\n",
    "                    \n",
    "                    dictionary = {'AIC': results.aic, 'AICc': AICc, 'BIC': results.bic, 'Cond_No': results.condition_number, 'Model': model_name,\n",
    "                                  'r2': results.rsquared, 'No_terms': len(model), 'Kfold': sum(score)/len(score)}\n",
    "                    \n",
    "                    total_subset.append(dictionary)\n",
    "\n",
    "\n",
    "\n",
    "                    if AIC_cur < AIC_prev:\n",
    "                        \n",
    "                        AIC_prev = AIC_cur\n",
    "                        final_model = [model, results, AIC_cur]\n",
    "                \n",
    "                    if av_score_prev < av_score:\n",
    "\n",
    "                        av_score_prev= av_score\n",
    "                        final_model_kfold = [model, results, av_score]                \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return final_model, total_subset, final_model_kfold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experimental_file = 'experimental.csv'\n",
    "response_file = 'Response.csv'\n",
    "\n",
    "\n",
    "test1 = 'rheomix final deg time min'\n",
    "test2 = 'rheomix stability time min'\n",
    "response = test1\n",
    "k_folds = 10\n",
    "\n",
    "\n",
    "final_model, total_subset, final_model_kfold = fit_model(experimental_file, response_file, response, k_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(total_subset)\n",
    "df.to_csv(\"FINAL_K=\" + str(k_folds) '_Total_model_subset_'  + response + \".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[['Xpvc', 0],\n",
       "   ['Xfiller', 1],\n",
       "   ['Xstabiliser', 3],\n",
       "   ['Xdinp', 4],\n",
       "   ['Xldh', 5],\n",
       "   ['Xstabiliser*Xldh', 3, 5],\n",
       "   ['Xdinp*Xldh', 4, 5]],\n",
       "  <statsmodels.regression.linear_model.RegressionResultsWrapper at 0xa14c9b5dd8>,\n",
       "  16.53370090020981],\n",
       " <class 'statsmodels.iolib.summary.Summary'>\n",
       " \"\"\"\n",
       "                                  OLS Regression Results                                \n",
       " =======================================================================================\n",
       " Dep. Variable:                      y   R-squared (uncentered):                   0.886\n",
       " Model:                            OLS   Adj. R-squared (uncentered):              0.866\n",
       " Method:                 Least Squares   F-statistic:                              43.51\n",
       " Date:                Sun, 17 Nov 2019   Prob (F-statistic):                    1.76e-16\n",
       " Time:                        07:18:37   Log-Likelihood:                         0.20683\n",
       " No. Observations:                  46   AIC:                                      13.59\n",
       " Df Residuals:                      39   BIC:                                      26.39\n",
       " Df Model:                           7                                                  \n",
       " Covariance Type:            nonrobust                                                  \n",
       " ==============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       " ------------------------------------------------------------------------------\n",
       " x1            -1.2401      0.453     -2.737      0.009      -2.156      -0.324\n",
       " x2            -0.6730      0.421     -1.600      0.118      -1.524       0.178\n",
       " x3             8.3295      4.237      1.966      0.056      -0.240      16.899\n",
       " x4            -1.5095      0.857     -1.761      0.086      -3.244       0.225\n",
       " x5            -7.0130      6.117     -1.146      0.259     -19.386       5.361\n",
       " x6          -278.1469     99.508     -2.795      0.008    -479.422     -76.872\n",
       " x7           106.5174     23.086      4.614      0.000      59.821     153.214\n",
       " ==============================================================================\n",
       " Omnibus:                       11.296   Durbin-Watson:                   1.180\n",
       " Prob(Omnibus):                  0.004   Jarque-Bera (JB):               11.551\n",
       " Skew:                           0.964   Prob(JB):                      0.00310\n",
       " Kurtosis:                       4.520   Cond. No.                     1.49e+03\n",
       " ==============================================================================\n",
       " \n",
       " Warnings:\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       " [2] The condition number is large, 1.49e+03. This might indicate that there are\n",
       " strong multicollinearity or other numerical problems.\n",
       " \"\"\",\n",
       " [[['Xpvc', 0], ['Xdinp', 4], ['Xldh', 5], ['Xdinp*Xldh', 4, 5]],\n",
       "  <statsmodels.regression.linear_model.RegressionResultsWrapper at 0xa14c793ef0>,\n",
       "  0.46784762941762],\n",
       " <class 'statsmodels.iolib.summary.Summary'>\n",
       " \"\"\"\n",
       "                                  OLS Regression Results                                \n",
       " =======================================================================================\n",
       " Dep. Variable:                      y   R-squared (uncentered):                   0.859\n",
       " Model:                            OLS   Adj. R-squared (uncentered):              0.846\n",
       " Method:                 Least Squares   F-statistic:                              64.14\n",
       " Date:                Sun, 17 Nov 2019   Prob (F-statistic):                    2.47e-17\n",
       " Time:                        07:18:37   Log-Likelihood:                         -4.7267\n",
       " No. Observations:                  46   AIC:                                      17.45\n",
       " Df Residuals:                      42   BIC:                                      24.77\n",
       " Df Model:                           4                                                  \n",
       " Covariance Type:            nonrobust                                                  \n",
       " ==============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       " ------------------------------------------------------------------------------\n",
       " x1            -0.7310      0.353     -2.072      0.044      -1.443      -0.019\n",
       " x2            -1.9072      0.884     -2.157      0.037      -3.692      -0.123\n",
       " x3           -19.0605      4.808     -3.965      0.000     -28.763      -9.358\n",
       " x4           123.3097     23.339      5.283      0.000      76.209     170.410\n",
       " ==============================================================================\n",
       " Omnibus:                        4.953   Durbin-Watson:                   1.186\n",
       " Prob(Omnibus):                  0.084   Jarque-Bera (JB):                4.014\n",
       " Skew:                           0.709   Prob(JB):                        0.134\n",
       " Kurtosis:                       3.289   Cond. No.                         326.\n",
       " ==============================================================================\n",
       " \n",
       " Warnings:\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       " \"\"\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model, final_model[1].summary(), final_model_kfold, final_model_kfold[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.plot(CN_hist, AIC_hist, 'r*')\n",
    "# plt.axis([0, 2000, 12, 20])\n",
    "# plt.xlabel('CN')\n",
    "# plt.ylabel('AIC')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.plot(VIF_max_hist, AIC_hist1, 'r*')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.scatter(CN_hist1, AIC_hist1, c = VIF_max_hist, vmin=0, vmax=50)\n",
    "# # plt.axis([0, 1000, 12, 20])\n",
    "# plt.xlabel('CN')\n",
    "# plt.ylabel('AIC')\n",
    "# plt.colorbar()\n",
    "# # plt.set_label('VIF')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = Axes3D(fig)\n",
    "\n",
    "# ax.scatter(CN_hist1,VIF_max_hist, AIC_hist1)\n",
    "# plt.xlabel('CN')\n",
    "# plt.ylabel('VIF')\n",
    "# ax.set_zlabel('AIC')\n",
    "# # plt.axis([0, 1000, 12, 18])\n",
    "# # plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(model_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in model_subset:\n",
    "#     if i[2] < 550 and i[2] > 450:\n",
    "#         a = []\n",
    "#         for j in i[0]:\n",
    "#             a.append(j[0])\n",
    "#         print('----model:', a, 'AIC', round(i[1], 3), 'CN:', round(i[2], 3), 'vif_max:', round(i[3], 3), 'R2:', round(i[4], 3), '----'\n",
    "#              )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
