{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import statsmodels.api as sm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_data(experimental_file, response_file, response):\n",
    "    'imports data'\n",
    "    'experimental_file = experimental design csv filename i.e experimental.csv'\n",
    "    'response_file = results csv filename i.e Response.csv'\n",
    "    'response = reponse name: i.e rheomix final deg time min or rheomix stability time min'\n",
    "    \n",
    "    experimental_df = pd.read_csv(experimental_file)\n",
    "    response_df = pd.read_csv(response_file)\n",
    "    \n",
    "    X = experimental_df[experimental_df.columns.values.tolist()[1:]].values\n",
    "    y = response_df[response].values\n",
    "    max1 = max(y)\n",
    "    min1 = min(y)\n",
    "\n",
    "    y_norm = [2*((i-min1)/(max1-min1)) - 1 for i in y]\n",
    "    \n",
    "    \n",
    "    X_linear = X\n",
    "    linear_terms = experimental_df.columns.values.tolist()[1:]\n",
    "    \n",
    "    return y_norm, X_linear, linear_terms, experimental_df, response_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def X_gen(model, X_linear):\n",
    "\n",
    "    for i, j in enumerate(model):\n",
    "        \n",
    "        if i == 0 and len(j) == 2: \n",
    "            X_new = X_linear[:, model[0][1]]\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            if len(j) == 2:\n",
    "                add = X_linear[:, j[1]]\n",
    "\n",
    "            if len(j) == 3:\n",
    "                add = X_linear[:, j[1]]*X_linear[:, j[2]]\n",
    "\n",
    "            X_new2 = np.column_stack((X_new, add))\n",
    "            X_new = X_new2\n",
    "\n",
    "    \n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "# linear_terms = experimental_df.columns.values.tolist()[1:]\n",
    "\n",
    "\n",
    "\n",
    "def fit_model(experimental_file, response_file, response):\n",
    "\n",
    "    y, X_linear, linear_terms, experimental_df, response_df = import_data(experimental_file, response_file, response)\n",
    "    lin_terms = []\n",
    "    AIC_prev = 1000\n",
    "\n",
    "    for i in range(len(linear_terms)):\n",
    "        term = linear_terms[i]\n",
    "        key = i\n",
    "        lin_terms.append([term, i])\n",
    "\n",
    "    cnt = 0\n",
    "    for i in range(len(lin_terms)):\n",
    "        for j in combinations(lin_terms, i+1):\n",
    "            linear_terms = list(j)\n",
    "\n",
    "\n",
    "            model = [a for a in linear_terms]\n",
    "            cnt+=1\n",
    "\n",
    "            X = X_gen(model, X_linear)\n",
    "\n",
    "            model_fit = sm.OLS(y, X)\n",
    "            results = model_fit.fit()\n",
    "            AIC_cur = results.aic\n",
    "\n",
    "\n",
    "            if AIC_cur < AIC_prev:\n",
    "\n",
    "                AIC_prev = AIC_cur\n",
    "                final_model = [model, results, AIC_cur]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            poss_terms = []\n",
    "            for i in range(len(linear_terms)):\n",
    "                for j in range(len(linear_terms)): \n",
    "                    if i < j:\n",
    "                        poss_terms.append([linear_terms[i][0] + '*' + linear_terms[j][0],  linear_terms[i][1], linear_terms[j][1]])\n",
    "\n",
    "\n",
    "\n",
    "            for m in range(1, len(poss_terms) + 1):\n",
    "                for k in combinations(poss_terms, m):\n",
    "\n",
    "                    model = [a for a in linear_terms]\n",
    "                    for i in range(m):\n",
    "                        model.append(k[i])\n",
    "\n",
    "                    cnt +=1\n",
    "                    X = X_gen(model, X_linear)\n",
    "\n",
    "                    model_fit = sm.OLS(y, X)\n",
    "                    results = model_fit.fit()\n",
    "                    AIC_cur = results.aic\n",
    "\n",
    "\n",
    "\n",
    "                    if AIC_cur < AIC_prev:\n",
    "\n",
    "                        AIC_prev = AIC_cur\n",
    "                        final_model = [model, results, AIC_cur]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return final_model[0], final_model[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_file = 'experimental.csv'\n",
    "response_file = 'Response.csv'\n",
    "\n",
    "\n",
    "test1 = 'rheomix final deg time min'\n",
    "test2 = 'rheomix stability time min'\n",
    "response = test2\n",
    "\n",
    "\n",
    "model, results = fit_model(experimental_file, response_file, response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['Xpvc', 0],\n",
       "  ['Xfiller', 1],\n",
       "  ['Xstabiliser', 3],\n",
       "  ['Xdinp', 4],\n",
       "  ['Xldh', 5],\n",
       "  ['Xfiller*Xldh', 1, 5],\n",
       "  ['Xstabiliser*Xldh', 3, 5],\n",
       "  ['Xdinp*Xldh', 4, 5]],\n",
       " <class 'statsmodels.iolib.summary.Summary'>\n",
       " \"\"\"\n",
       "                             OLS Regression Results                            \n",
       " ==============================================================================\n",
       " Dep. Variable:                      y   R-squared:                       0.888\n",
       " Model:                            OLS   Adj. R-squared:                  0.864\n",
       " Method:                 Least Squares   F-statistic:                     37.62\n",
       " Date:                Wed, 11 Sep 2019   Prob (F-statistic):           9.63e-16\n",
       " Time:                        19:56:02   Log-Likelihood:                 1.2433\n",
       " No. Observations:                  46   AIC:                             13.51\n",
       " Df Residuals:                      38   BIC:                             28.14\n",
       " Df Model:                           8                                         \n",
       " Covariance Type:            nonrobust                                         \n",
       " ==============================================================================\n",
       "                  coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       " ------------------------------------------------------------------------------\n",
       " x1            -1.9477      0.528     -3.691      0.001        -3.016    -0.879\n",
       " x2            -0.4201      0.709     -0.592      0.557        -1.856     1.016\n",
       " x3            20.6119      4.480      4.601      0.000        11.542    29.682\n",
       " x4            -0.6177      0.878     -0.704      0.486        -2.395     1.159\n",
       " x5            -1.8836      7.474     -0.252      0.802       -17.013    13.246\n",
       " x6           -35.2410     21.646     -1.628      0.112       -79.060     8.578\n",
       " x7          -436.3010    103.510     -4.215      0.000      -645.847  -226.755\n",
       " x8            99.4566     24.239      4.103      0.000        50.388   148.525\n",
       " ==============================================================================\n",
       " Omnibus:                       14.073   Durbin-Watson:                   1.593\n",
       " Prob(Omnibus):                  0.001   Jarque-Bera (JB):               19.096\n",
       " Skew:                           0.962   Prob(JB):                     7.14e-05\n",
       " Kurtosis:                       5.503   Cond. No.                     1.57e+03\n",
       " ==============================================================================\n",
       " \n",
       " Warnings:\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       " [2] The condition number is large, 1.57e+03. This might indicate that there are\n",
       " strong multicollinearity or other numerical problems.\n",
       " \"\"\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
